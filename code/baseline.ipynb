{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT for NER on Video Comments\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Load video comment data from a CSV file.\n",
    "2. Preprocess the data and align token-level labels.\n",
    "3. Fine-tune a pre-trained BERT model (using Hugging Face Transformers) for Named Entity Recognition.\n",
    "4. Evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: BERT-NER\n",
    "\n",
    "This notebook implements a baseline Named Entity Recognition (NER) model using a fine-tuned BERT architecture. It serves as the foundation for evaluating improvements introduced by contextual embeddings and clustering methods in our final pipeline.\n",
    "\n",
    "We evaluate the model using standard NER metrics (precision, recall, F1-score) on a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: seqeval in /opt/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/anaconda3/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/anaconda3/lib/python3.11/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers seqeval torch \"accelerate>=0.26.0\"\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "if not hasattr(torch, \"get_default_device\"):\n",
    "    torch.get_default_device = lambda: torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorForTokenClassification)\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Likes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Replies",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Relevance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Feature request",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Problem report",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Efficiency",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tokens",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "labels",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_entity",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "entity_tokens",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "combined_labels_str",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a1425fbc-b42f-4a6e-bc09-7e0bbfeaa9c7",
       "rows": [
        [
         "0",
         "UghhPYDEB6B173gCoAEC",
         "2017-04-28T18:12:45Z",
         "Aaron Brown",
         "1679",
         "30",
         "i want what he's smoking",
         "spam",
         "neutral",
         "False",
         "False",
         "False",
         "false",
         "['i', 'want', 'what', 'he', \"'s\", 'smoking']",
         "['spam', 'neutral', False, False, False, 'false']",
         "6",
         "True",
         "['i', 'want', 'what', 'he', \"'s\", 'smoking']",
         "False, False, False, false, neutral, spam"
        ],
        [
         "1",
         "Ugh6WAPQinruAHgCoAEC",
         "2017-04-28T18:15:14Z",
         "Felician Cadar",
         "684",
         "22",
         "I love how Musk always makes seemingly wild claims that turn out to be reasonable ideas, conclusions of first principles reasoning.",
         "spam",
         "positive",
         "False",
         "False",
         "False",
         "false",
         "['I', 'love', 'how', 'Musk', 'always', 'makes', 'seemingly', 'wild', 'claims', 'that', 'turn', 'out', 'to', 'be', 'reasonable', 'ideas', ',', 'conclusions', 'of', 'first', 'principles', 'reasoning', '.']",
         "['spam', 'positive', False, False, False, 'false']",
         "23",
         "True",
         "['I', 'love', 'how', 'Musk', 'always', 'makes']",
         "False, False, False, false, positive, spam"
        ],
        [
         "2",
         "Ugj9xobHmVeDEHgCoAEC",
         "2017-04-28T18:24:53Z",
         "Kelvin Yang",
         "0",
         "0",
         "No.3",
         "spam",
         "neutral",
         "False",
         "False",
         "False",
         "false",
         "['No.3']",
         "['spam', 'neutral', False, False, False, 'false']",
         "1",
         "True",
         "['No.3']",
         "False, False, False, false, neutral, spam"
        ],
        [
         "3",
         "Ugj39PRg5dVn8XgCoAEC",
         "2017-04-28T18:25:31Z",
         "Kelvin Yang",
         "140",
         "4",
         "Could be the start of a historical company",
         "spam",
         "neutral",
         "False",
         "False",
         "False",
         "false",
         "['Could', 'be', 'the', 'start', 'of', 'a', 'historical', 'company']",
         "['spam', 'neutral', False, False, False, 'false']",
         "8",
         "True",
         "['Could', 'be', 'the', 'start', 'of', 'a']",
         "False, False, False, false, neutral, spam"
        ],
        [
         "4",
         "Ugiu9jMmiWts1HgCoAEC",
         "2017-04-28T18:31:52Z",
         "serendipity42",
         "675",
         "9",
         "Gotta start somewhere before making tunnels on Mars",
         "spam",
         "neutral",
         "False",
         "False",
         "False",
         "false",
         "['Got', 'ta', 'start', 'somewhere', 'before', 'making', 'tunnels', 'on', 'Mars']",
         "['spam', 'neutral', False, False, False, 'false']",
         "9",
         "True",
         "['Got', 'ta', 'start', 'somewhere', 'before', 'making']",
         "False, False, False, false, neutral, spam"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Feature request</th>\n",
       "      <th>Problem report</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>Safety</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>has_entity</th>\n",
       "      <th>entity_tokens</th>\n",
       "      <th>combined_labels_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UghhPYDEB6B173gCoAEC</td>\n",
       "      <td>2017-04-28T18:12:45Z</td>\n",
       "      <td>Aaron Brown</td>\n",
       "      <td>1679</td>\n",
       "      <td>30</td>\n",
       "      <td>i want what he's smoking</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>['i', 'want', 'what', 'he', \"'s\", 'smoking']</td>\n",
       "      <td>['spam', 'neutral', False, False, False, 'false']</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>['i', 'want', 'what', 'he', \"'s\", 'smoking']</td>\n",
       "      <td>False, False, False, false, neutral, spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugh6WAPQinruAHgCoAEC</td>\n",
       "      <td>2017-04-28T18:15:14Z</td>\n",
       "      <td>Felician Cadar</td>\n",
       "      <td>684</td>\n",
       "      <td>22</td>\n",
       "      <td>I love how Musk always makes seemingly wild cl...</td>\n",
       "      <td>spam</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>['I', 'love', 'how', 'Musk', 'always', 'makes'...</td>\n",
       "      <td>['spam', 'positive', False, False, False, 'fal...</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>['I', 'love', 'how', 'Musk', 'always', 'makes']</td>\n",
       "      <td>False, False, False, false, positive, spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugj9xobHmVeDEHgCoAEC</td>\n",
       "      <td>2017-04-28T18:24:53Z</td>\n",
       "      <td>Kelvin Yang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No.3</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>['No.3']</td>\n",
       "      <td>['spam', 'neutral', False, False, False, 'false']</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>['No.3']</td>\n",
       "      <td>False, False, False, false, neutral, spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugj39PRg5dVn8XgCoAEC</td>\n",
       "      <td>2017-04-28T18:25:31Z</td>\n",
       "      <td>Kelvin Yang</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>Could be the start of a historical company</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>['Could', 'be', 'the', 'start', 'of', 'a', 'hi...</td>\n",
       "      <td>['spam', 'neutral', False, False, False, 'false']</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>['Could', 'be', 'the', 'start', 'of', 'a']</td>\n",
       "      <td>False, False, False, false, neutral, spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugiu9jMmiWts1HgCoAEC</td>\n",
       "      <td>2017-04-28T18:31:52Z</td>\n",
       "      <td>serendipity42</td>\n",
       "      <td>675</td>\n",
       "      <td>9</td>\n",
       "      <td>Gotta start somewhere before making tunnels on...</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>['Got', 'ta', 'start', 'somewhere', 'before', ...</td>\n",
       "      <td>['spam', 'neutral', False, False, False, 'false']</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>['Got', 'ta', 'start', 'somewhere', 'before', ...</td>\n",
       "      <td>False, False, False, false, neutral, spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                  Date          Author  Likes  Replies  \\\n",
       "0  UghhPYDEB6B173gCoAEC  2017-04-28T18:12:45Z     Aaron Brown   1679       30   \n",
       "1  Ugh6WAPQinruAHgCoAEC  2017-04-28T18:15:14Z  Felician Cadar    684       22   \n",
       "2  Ugj9xobHmVeDEHgCoAEC  2017-04-28T18:24:53Z     Kelvin Yang      0        0   \n",
       "3  Ugj39PRg5dVn8XgCoAEC  2017-04-28T18:25:31Z     Kelvin Yang    140        4   \n",
       "4  Ugiu9jMmiWts1HgCoAEC  2017-04-28T18:31:52Z   serendipity42    675        9   \n",
       "\n",
       "                                             Comment Relevance  Polarity  \\\n",
       "0                           i want what he's smoking      spam   neutral   \n",
       "1  I love how Musk always makes seemingly wild cl...      spam  positive   \n",
       "2                                               No.3      spam   neutral   \n",
       "3         Could be the start of a historical company      spam   neutral   \n",
       "4  Gotta start somewhere before making tunnels on...      spam   neutral   \n",
       "\n",
       "   Feature request  Problem report  Efficiency Safety  \\\n",
       "0            False           False       False  false   \n",
       "1            False           False       False  false   \n",
       "2            False           False       False  false   \n",
       "3            False           False       False  false   \n",
       "4            False           False       False  false   \n",
       "\n",
       "                                              tokens  \\\n",
       "0       ['i', 'want', 'what', 'he', \"'s\", 'smoking']   \n",
       "1  ['I', 'love', 'how', 'Musk', 'always', 'makes'...   \n",
       "2                                           ['No.3']   \n",
       "3  ['Could', 'be', 'the', 'start', 'of', 'a', 'hi...   \n",
       "4  ['Got', 'ta', 'start', 'somewhere', 'before', ...   \n",
       "\n",
       "                                              labels  num_tokens  has_entity  \\\n",
       "0  ['spam', 'neutral', False, False, False, 'false']           6        True   \n",
       "1  ['spam', 'positive', False, False, False, 'fal...          23        True   \n",
       "2  ['spam', 'neutral', False, False, False, 'false']           1        True   \n",
       "3  ['spam', 'neutral', False, False, False, 'false']           8        True   \n",
       "4  ['spam', 'neutral', False, False, False, 'false']           9        True   \n",
       "\n",
       "                                       entity_tokens  \\\n",
       "0       ['i', 'want', 'what', 'he', \"'s\", 'smoking']   \n",
       "1    ['I', 'love', 'how', 'Musk', 'always', 'makes']   \n",
       "2                                           ['No.3']   \n",
       "3         ['Could', 'be', 'the', 'start', 'of', 'a']   \n",
       "4  ['Got', 'ta', 'start', 'somewhere', 'before', ...   \n",
       "\n",
       "                          combined_labels_str  \n",
       "0   False, False, False, false, neutral, spam  \n",
       "1  False, False, False, false, positive, spam  \n",
       "2   False, False, False, false, neutral, spam  \n",
       "3   False, False, False, false, neutral, spam  \n",
       "4   False, False, False, false, neutral, spam  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df = pd.read_csv('../data/4698969/Dataset_updated.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4275, 18)\n",
      "Columns: Index(['ID', 'Date', 'Author', 'Likes', 'Replies', 'Comment', 'Relevance',\n",
      "       'Polarity', 'Feature request', 'Problem report', 'Efficiency', 'Safety',\n",
      "       'tokens', 'labels', 'num_tokens', 'has_entity', 'entity_tokens',\n",
      "       'combined_labels_str'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Format Assumptions\n",
    "\n",
    "For this notebook we assume:\n",
    "\n",
    "- **Comment:** contains the raw comment text.\n",
    "- **combined_labels_str:** contains a string representation of a list of token-level BIO labels (aligned to a whitespace tokenization of the comment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Label Set\n",
    "\n",
    "We scan through the dataset to extract all unique labels from the combined_labels_str column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract named entities from comments\n",
    "comment_entities = []\n",
    "\n",
    "for text in df['Comment'].dropna():\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        comment_entities.append((ent.text.strip(), ent.label_))\n",
    "\n",
    "# Create DataFrame of entities\n",
    "entity_df = pd.DataFrame(comment_entities, columns=[\"Entity\", \"Label\"])\n",
    "people_keywords = set(entity_df[entity_df[\"Label\"] == \"PERSON\"][\"Entity\"].str.lower())\n",
    "org_keywords = set(entity_df[entity_df[\"Label\"] == \"ORG\"][\"Entity\"].str.lower())\n",
    "brand_keywords = set(entity_df[entity_df[\"Label\"].isin([\"PRODUCT\", \"WORK_OF_ART\"])][\"Entity\"].str.lower())\n",
    "\n",
    "# Show top 10 most frequent entities per type\n",
    "top_entities_by_type = entity_df.groupby(\"Label\")[\"Entity\"].value_counts().groupby(level=0).head(10)\n",
    "print(top_entities_by_type.reset_index(name=\"Count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to assign BIO-style labels ---\n",
    "def generate_synthetic_labels(tokens):\n",
    "    return [\n",
    "        \"B-PER\" if token.lower() in people_keywords else\n",
    "        \"B-ORG\" if token.lower() in org_keywords else\n",
    "        \"B-PROD\" if token.lower() in brand_keywords else\n",
    "        \"O\"\n",
    "        for token in tokens\n",
    "    ]\n",
    "\n",
    "# Apply labeling to the token column\n",
    "df[\"synthetic_labels\"] = df[\"tokens\"].apply(generate_synthetic_labels)\n",
    "\n",
    "# Save to variables for training\n",
    "texts = df[\"tokens\"].tolist()\n",
    "labels = df[\"synthetic_labels\"].tolist()\n",
    "\n",
    "# Preview one example\n",
    "for token, label in zip(texts[0], labels[0]):\n",
    "    print(f\"{token:>10}  →  {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom PyTorch Dataset for NER\n",
    "\n",
    "This dataset:\n",
    "- Uses the **Comment** column as the raw text.\n",
    "- Uses the **combined_labels_str** column (parsed into a list) as the token-level labels.\n",
    "- Tokenizes the text using BERT's tokenizer with `is_split_into_words=True` and aligns the provided labels with the sub-tokens.\n",
    "\n",
    "Note: The text is first split by whitespace so that the provided labels (which were created with a whitespace tokenization) align with the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into Training and Validation\n",
    "\n",
    "We'll use scikit-learn’s train_test_split to separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 70/15/15 Train/Validation/Test Split ===\n",
    "\n",
    "# First split: 70% train, 30% temp (val + test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 15% val, 15% test (from 30% temp)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_texts)}, Validation size: {len(val_texts)}, Test size: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model.\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(labels_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3420\n",
      "Number of validation examples: 855\n"
     ]
    }
   ],
   "source": [
    "# Create our custom datasets for training and validation.\n",
    "train_dataset = CustomNERDataset(train_df, tokenizer, label_to_id)\n",
    "val_dataset = CustomNERDataset(val_df, tokenizer, label_to_id)\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomNERDataset object at 0x18ab00890>\n",
      "Tokenized input keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Tokens: ['[CLS]', 'Te', '##sla', 'claims', 'the', 'future', 'is', 'self', 'driving', 'car', ',', 'but', 'now', 'shows', 'their', 'future', 'is', 'a', 'car', 'on', 'a', 'flat', 'bed', 'rail', 'car', 'that', 'follows', 'a', 'rail', '.', 'What', 'a', 'mi', '##s', '##fire', '.', 'For', 'such', 'a', 'simple', 'and', 'regulated', 'environment', 'as', 'a', 'car', 'only', 'tunnel', ',', 'it', 'would', 'actually', 'be', 'much', 'easier', 'to', 'make', 'car', 'self', 'drive', 'than', 'on', 'a', 'open', 'road', '.', '[SEP]']\n",
      "Aligned Labels: ['-100', 'False', 'False', 'False', 'False', 'false', 'neutral', 'spam', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100', '-100']\n"
     ]
    }
   ],
   "source": [
    "# Inspect one tokenized sample from the training dataset.\n",
    "print(train_dataset)\n",
    "sample = train_dataset[0]\n",
    "print(\"Tokenized input keys:\", sample.keys())\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(sample[\"input_ids\"]))\n",
    "print(\"Aligned Labels:\", [id_to_label[l] if l != -100 else \"-100\" for l in sample[\"labels\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collator and Evaluation Metrics\n",
    "\n",
    "We use the Hugging Face DataCollator for token classification and define a compute_metrics function using seqeval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        curr_labels = []\n",
    "        curr_preds = []\n",
    "        for pred, label in zip(pred_seq, label_seq):\n",
    "            if label != -100:\n",
    "                curr_labels.append(id_to_label[label])\n",
    "                curr_preds.append(id_to_label[pred])\n",
    "        true_labels.append(curr_labels)\n",
    "        true_predictions.append(curr_preds)\n",
    "    \n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "    # Uncomment the following line for a detailed report:\n",
    "    # print(classification_report(true_labels, true_predictions))\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments and Trainer Setup\n",
    "\n",
    "Adjust the training parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../report/bert-ner-video-comments\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../report/logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/6ytyl_l54r34xk4zb10_hq680000gn/T/ipykernel_29437/4177837641.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1284' max='1284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1284/1284 06:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.625496</td>\n",
       "      <td>0.528057</td>\n",
       "      <td>0.572661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.427282</td>\n",
       "      <td>0.641906</td>\n",
       "      <td>0.626047</td>\n",
       "      <td>0.633877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.425186</td>\n",
       "      <td>0.687881</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>0.674071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: False seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: false seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ham seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: negative seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: neutral seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: spam seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: true seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: True seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: positive seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: False seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: false seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ham seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: negative seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: neutral seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: spam seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: true seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: True seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: positive seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: False seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: false seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ham seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: negative seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: neutral seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: spam seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: true seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: True seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: positive seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1284, training_loss=0.5447256332988679, metrics={'train_runtime': 365.0513, 'train_samples_per_second': 28.106, 'train_steps_per_second': 3.517, 'total_flos': 319729063427856.0, 'train_loss': 0.5447256332988679, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.4251856803894043, 'eval_precision': 0.6878814298169137, 'eval_recall': 0.6608040201005025, 'eval_f1': 0.6740709098675779, 'eval_runtime': 5.6937, 'eval_samples_per_second': 150.165, 'eval_steps_per_second': 18.793, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: False seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: false seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ham seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: negative seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: neutral seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: spam seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: true seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: True seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: positive seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation on Test Set ===\n",
    "y_pred = predict_entities(test_texts)  # Should return List[List[str]] same as test_labels\n",
    "\n",
    "print(\"NER Evaluation on Test Set:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "\n",
    "# Print metrics explicitly\n",
    "precision = precision_score(test_labels, y_pred)\n",
    "recall = recall_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall:    {recall:.2%}\")\n",
    "print(f\"F1 Score:  {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Example\n",
    "\n",
    "Test the model on a new comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['This', 'new', 'update', 'totally', 'changed', 'the', 'way', 'I', 'see', 'the', 'future', 'of', 'tech', '!']\n",
      "Predicted Labels: ['False', 'False', 'False', 'False', 'false', 'neutral', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam']\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This new update totally changed the way I see the future of tech!\"\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "predicted_labels = [id_to_label[p] for p in predictions[0].tolist()]\n",
    "tokens = tokenizer.tokenize(test_text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Baseline Results\n",
    "\n",
    "The BERT-NER model performs reasonably well on standard entities like people and organizations, but struggles with informal/slang terms and context-dependent mentions often seen in video comments.\n",
    "\n",
    "This highlights the need for incorporating contextual embeddings and clustering approaches to handle variant spellings and implicit references, which we address in the extended model pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
