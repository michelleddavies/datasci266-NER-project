{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT for NER on Video Comments\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Load video comment data from a CSV file.\n",
    "2. Preprocess the data and align token-level labels.\n",
    "3. Fine-tune a pre-trained BERT model (using Hugging Face Transformers) for Named Entity Recognition.\n",
    "4. Evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: BERT-NER\n",
    "\n",
    "This notebook implements a baseline Named Entity Recognition (NER) model using a fine-tuned BERT architecture. It serves as the foundation for evaluating improvements introduced by contextual embeddings and clustering methods in our final pipeline.\n",
    "\n",
    "We evaluate the model using standard NER metrics (precision, recall, F1-score) on a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers seqeval torch \"accelerate>=0.26.0\"\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "if not hasattr(torch, \"get_default_device\"):\n",
    "    torch.get_default_device = lambda: torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorForTokenClassification)\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df = pd.read_csv('../data/4698969/Dataset_updated.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Format Assumptions\n",
    "\n",
    "For this notebook we assume:\n",
    "\n",
    "- **Comment:** contains the raw comment text.\n",
    "- **combined_labels_str:** contains a string representation of a list of token-level BIO labels (aligned to a whitespace tokenization of the comment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Label Set\n",
    "\n",
    "We scan through the dataset to extract all unique labels from the combined_labels_str column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract named entities from comments\n",
    "comment_entities = []\n",
    "\n",
    "for text in df['Comment'].dropna():\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        comment_entities.append((ent.text.strip(), ent.label_))\n",
    "\n",
    "# Create DataFrame of entities\n",
    "entity_df = pd.DataFrame(comment_entities, columns=[\"Entity\", \"Label\"])\n",
    "people_keywords = set(entity_df[entity_df[\"Label\"] == \"PERSON\"][\"Entity\"].str.lower())\n",
    "org_keywords = set(entity_df[entity_df[\"Label\"] == \"ORG\"][\"Entity\"].str.lower())\n",
    "brand_keywords = set(entity_df[entity_df[\"Label\"].isin([\"PRODUCT\", \"WORK_OF_ART\"])][\"Entity\"].str.lower())\n",
    "\n",
    "# Show top 10 most frequent entities per type\n",
    "top_entities_by_type = entity_df.groupby(\"Label\")[\"Entity\"].value_counts().groupby(level=0).head(10)\n",
    "print(top_entities_by_type.reset_index(name=\"Count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to assign BIO-style labels ---\n",
    "def generate_synthetic_labels(tokens):\n",
    "    return [\n",
    "        \"B-PER\" if token.lower() in people_keywords else\n",
    "        \"B-ORG\" if token.lower() in org_keywords else\n",
    "        \"B-PROD\" if token.lower() in brand_keywords else\n",
    "        \"O\"\n",
    "        for token in tokens\n",
    "    ]\n",
    "\n",
    "# Apply labeling to the token column\n",
    "df[\"synthetic_labels\"] = df[\"tokens\"].apply(generate_synthetic_labels)\n",
    "\n",
    "# Save to variables for training\n",
    "texts = df[\"tokens\"].tolist()\n",
    "labels = df[\"synthetic_labels\"].tolist()\n",
    "\n",
    "# Preview one example\n",
    "for token, label in zip(texts[0], labels[0]):\n",
    "    print(f\"{token:>10}  →  {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom PyTorch Dataset for NER\n",
    "\n",
    "This dataset:\n",
    "- Uses the **Comment** column as the raw text.\n",
    "- Uses the **combined_labels_str** column (parsed into a list) as the token-level labels.\n",
    "- Tokenizes the text using BERT's tokenizer with `is_split_into_words=True` and aligns the provided labels with the sub-tokens.\n",
    "\n",
    "Note: The text is first split by whitespace so that the provided labels (which were created with a whitespace tokenization) align with the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNERDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, label_to_id, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_id = label_to_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx]\n",
    "        tags = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        word_ids = encoding.word_ids(batch_index=0)\n",
    "        label_ids = []\n",
    "\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(self.label_to_id[tags[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(-100)  # mask subword tokens\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        encoding[\"labels\"] = torch.tensor(label_ids)\n",
    "        return {k: v.squeeze() for k, v in encoding.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into Training and Validation\n",
    "\n",
    "We'll use scikit-learn’s train_test_split to separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 70/15/15 Train/Validation/Test Split ===\n",
    "\n",
    "# First split: 70% train, 30% temp (val + test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 15% val, 15% test (from 30% temp)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_texts)}, Validation size: {len(val_texts)}, Test size: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all label lists and get the unique labels\n",
    "unique_labels = sorted({label for label_seq in labels for label in label_seq})\n",
    "print(\"Label Set:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for the model\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with correct label mappings\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our custom datasets for training and validation.\n",
    "# Create dataset objects\n",
    "train_dataset = CustomNERDataset(train_texts, train_labels, tokenizer, label_to_id)\n",
    "val_dataset = CustomNERDataset(val_texts, val_labels, tokenizer, label_to_id)\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomNERDataset(test_texts, test_labels, tokenizer, label_to_id)\n",
    "print(\"Number of test examples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect one tokenized sample from the training dataset.\n",
    "print(train_dataset)\n",
    "sample = train_dataset[0]\n",
    "print(\"Tokenized input keys:\", sample.keys())\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(sample[\"input_ids\"]))\n",
    "print(\"Aligned Labels:\", [id_to_label[l] if l != -100 else \"-100\" for l in sample[\"labels\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collator and Evaluation Metrics\n",
    "\n",
    "We use the Hugging Face DataCollator for token classification and define a compute_metrics function using seqeval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        curr_labels = []\n",
    "        curr_preds = []\n",
    "        for pred, label in zip(pred_seq, label_seq):\n",
    "            if label != -100:\n",
    "                curr_labels.append(id_to_label[label])\n",
    "                curr_preds.append(id_to_label[pred])\n",
    "        true_labels.append(curr_labels)\n",
    "        true_predictions.append(curr_preds)\n",
    "    \n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "    # Uncomment the following line for a detailed report:\n",
    "    # print(classification_report(true_labels, true_predictions))\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments and Trainer Setup\n",
    "\n",
    "Adjust the training parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../report/bert-ner-video-comments\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../report/logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(\"Test Metrics:\", metrics)\n",
    "# Save the model\n",
    "trainer.save_model(\"../report/bert-ner-video-comments/model-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "tokenizer.save_pretrained(\"../report/bert-ner-video-comments/tokenizer-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation on Test Set ===\n",
    "test_output = trainer.predict(test_dataset)\n",
    "predictions = test_output.predictions\n",
    "true_labels = test_output.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits to predicted class indices\n",
    "predictions = predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map predictions and true labels to tag names\n",
    "predicted_tags = []\n",
    "true_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_seq, label_seq in zip(predictions, true_labels):\n",
    "    pred_labels = []\n",
    "    true_labels_cleaned = []\n",
    "    for pred, label in zip(pred_seq, label_seq):\n",
    "        if label != -100:\n",
    "            pred_labels.append(id_to_label[pred])\n",
    "            true_labels_cleaned.append(id_to_label[label])\n",
    "    predicted_tags.append(pred_labels)\n",
    "    true_tags.append(true_labels_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print individual metrics\n",
    "precision = precision_score(true_tags, predicted_tags)\n",
    "recall = recall_score(true_tags, predicted_tags)\n",
    "f1 = f1_score(true_tags, predicted_tags)\n",
    "\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall:    {recall:.2%}\")\n",
    "print(f\"F1 Score:  {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full report\n",
    "print(\"NER Evaluation on Test Set:\")\n",
    "print(classification_report(true_tags, predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Example\n",
    "\n",
    "Test the model on a new comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"This new update totally changed the way I see the future of tech!\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input and get word ID mapping\n",
    "encoding = tokenizer(test_text, return_tensors=\"pt\", truncation=True, return_offsets_mapping=True, return_tensors=\"pt\", is_split_into_words=False)\n",
    "encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "offset_mapping = encoding.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding).logits\n",
    "predictions = torch.argmax(outputs, dim=2).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to labels, ignoring special tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())\n",
    "predicted_labels = []\n",
    "for token, pred_id in zip(tokens, predictions):\n",
    "    label = id_to_label[pred_id]\n",
    "    predicted_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Baseline Results\n",
    "\n",
    "The BERT-NER model performs reasonably well on standard entities like people and organizations, but struggles with informal/slang terms and context-dependent mentions often seen in video comments.\n",
    "\n",
    "This highlights the need for incorporating contextual embeddings and clustering approaches to handle variant spellings and implicit references, which we address in the extended model pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
